# Fricadelle - Guide de DÃ©marrage Rapide

## âš¡ Installation Rapide

```bash
# 1. Cloner le projet
git clone https://github.com/Shlakii/Fricadelle.git
cd Fricadelle

# 2. Installer les dÃ©pendances Python
pip install -r requirements.txt

# 3. Installer et lancer Ollama
# Voir: https://ollama.ai/download
ollama serve

# 4. TÃ©lÃ©charger un modÃ¨le IA (RECOMMANDÃ‰: qwen2.5:14b)
ollama pull qwen2.5:14b
# OU le modÃ¨le par dÃ©faut
ollama pull llama3.2
```

## ðŸš€ Utilisation en 5 Ã‰tapes

### Ã‰tape 1: Placer vos fichiers (N'IMPORTE QUOI!)
```bash
# Fricadelle accepte TOUT type de fichier:
# - Scans automatiques (nmap, nuclei, etc.)
# - Outputs de commandes (kerbrute, crackmapexec, etc.)
# - Notes manuelles (observations.txt)
# - Messages simples (findings.txt)
# - Tout format: JSON, XML, CSV, YAML, TXT, etc.

cp vos_scans/* results/scans/
# OU crÃ©er une note manuelle:
echo "RDP ouvert sur 192.168.1.50 sans restriction IP" > results/scans/note.txt
```

### Ã‰tape 2: Configurer le client
```bash
# Ã‰diter config.yaml
nano config.yaml
# Modifier: client_name, audit_date, scope, testeurs
```

### Ã‰tape 3: Analyser avec l'IA
```bash
# Avec le modÃ¨le RECOMMANDÃ‰ (meilleure qualitÃ©)
python parse_and_enrich.py --model qwen2.5:14b

# OU avec le modÃ¨le par dÃ©faut
python parse_and_enrich.py

# âœ… RÃ©sultat: results/findings_enrichis.json
```

### Ã‰tape 4: GÃ©nÃ©rer le rapport
```bash
python generate_report.py
# âœ… RÃ©sultat: output/rapport.pdf
```

### Ã‰tape 5: Livrer au client
```bash
# RÃ©cupÃ©rer le fichier
ls output/
# > rapport.pdf
```

## ðŸ“‹ Formats de Fichiers SupportÃ©s

| Type | Formats | Exemples |
|------|---------|----------|
| Scans Automatiques | JSON, XML | `nmap -sV -oJ scan.json target` |
| Outputs Commandes | TXT, CSV | `kerbrute > kerbrute.txt` |
| Notes Manuelles | TXT, MD | `echo "TrouvÃ© SQLi sur /login" > note.txt` |
| Messages Simples | TXT | `echo "Admin/admin marche sur FTP" > msg.txt` |
| DonnÃ©es StructurÃ©es | JSON, YAML, XML, CSV | Tout format structurÃ© |

**L'IA comprend et analyse INTELLIGEMMENT tout type de contenu!**

## ðŸŽ¨ Personnalisation Rapide

### Changer le modÃ¨le IA (RECOMMANDÃ‰)
```bash
# Voir AI_MODELS_GUIDE.md pour tous les modÃ¨les disponibles

# Installer le meilleur modÃ¨le pour l'analyse de sÃ©curitÃ©
ollama pull qwen2.5:14b

# Utiliser avec Fricadelle
python parse_and_enrich.py --model qwen2.5:14b

# OU Ã©diter fricadelle_config.yaml:
# ai:
#   model: "qwen2.5:14b"
```

### Changer le logo
```bash
cp mon_logo.png assets/logo.png
# Ã‰diter config.yaml:
# report:
#   logo_path: "assets/logo.png"
```

### Changer les couleurs
```bash
# Ã‰diter assets/style.css
# Modifier les classes .severity-badge
```

### Options en ligne de commande
```bash
# Voir toutes les options
python parse_and_enrich.py --help

# Exemples:
python parse_and_enrich.py --model qwen2.5:14b --quiet
python parse_and_enrich.py --scans-dir /path/to/scans
python parse_and_enrich.py --output custom_findings.json
python generate_report.py --output /mon/dossier
```

## ðŸ”§ Commandes Utiles

```bash
# Tester le template
python -c "from jinja2 import Environment, FileSystemLoader; \
env = Environment(loader=FileSystemLoader('templates')); \
template = env.get_template('rapport.html.j2'); print('âœ… Template OK')"

# VÃ©rifier Ollama
ollama list

# Voir l'aide
python generate_report.py --help
python parse_and_enrich.py --help
```

## ðŸ“ Structure du Projet

```
Fricadelle/
â”œâ”€â”€ parse_and_enrich.py         # Script d'analyse IA (AMÃ‰LIORÃ‰)
â”œâ”€â”€ generate_report.py          # Script de gÃ©nÃ©ration PDF
â”œâ”€â”€ config.yaml                 # Configuration audit/rapport
â”œâ”€â”€ fricadelle_config.yaml      # Configuration IA (NOUVEAU)
â”œâ”€â”€ requirements.txt            # DÃ©pendances
â”œâ”€â”€ AI_MODELS_GUIDE.md          # Guide modÃ¨les IA (NOUVEAU)
â”œâ”€â”€ README.md                   # Documentation complÃ¨te
â”œâ”€â”€ QUICKSTART.md               # Ce fichier
â”œâ”€â”€ ARCHITECTURE.md             # Architecture technique
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ rapport.html.j2        # Template Jinja2
â”œâ”€â”€ assets/
â”‚   â”œâ”€â”€ style.css              # Styles CSS modernes
â”‚   â””â”€â”€ logo.png               # Logo
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ scans/                 # â† TOUT TYPE DE FICHIER
â”‚   â””â”€â”€ findings_enrichis.json
â””â”€â”€ output/
    â””â”€â”€ rapport.pdf            # â† RAPPORT FINAL PDF
```

## â“ ProblÃ¨mes FrÃ©quents

### "ModuleNotFoundError: No module named 'ollama'"
```bash
pip install -r requirements.txt
```

### "Connection refused" (Ollama)
```bash
# Dans un terminal sÃ©parÃ©:
ollama serve
```

### "WeasyPrint error"
```bash
# Ubuntu/Debian:
sudo apt-get install libpango-1.0-0 libpangoft2-1.0-0

# macOS:
brew install pango
```

### Le PDF est vide
```bash
# VÃ©rifier que findings_enrichis.json existe et contient des donnÃ©es
cat results/findings_enrichis.json | jq '.findings | length'
```

## ðŸ“– Documentation ComplÃ¨te

- `README.md` - Documentation gÃ©nÃ©rale et vue d'ensemble
- `AI_MODELS_GUIDE.md` - **Guide complet des modÃ¨les IA** (NOUVEAU - Ã€ LIRE!)
- `ARCHITECTURE.md` - Architecture technique dÃ©taillÃ©e
- `fricadelle_config.yaml` - Configuration avancÃ©e de l'IA
- `example_usage.sh` - Script d'exemple

## ðŸŽ¯ Workflow RecommandÃ©

```bash
# 1. Effectuer les scans OU Ã©crire des notes
nmap -sV -oJ nmap.json 192.168.1.0/24
kerbrute passwordspray -d domain.local users.txt > kerbrute.txt

# OU crÃ©er une note manuelle:
cat > results/scans/observations.txt << EOF
Le serveur DC01 (192.168.1.10) a SMB signing dÃ©sactivÃ©.
Admin/admin fonctionne sur le FTP de 192.168.1.50.
RDP ouvert sur Internet sans restriction IP (port 3389).
EOF

# 2. Installer le meilleur modÃ¨le IA
ollama pull qwen2.5:14b

# 3. Configurer
nano config.yaml

# 4. Lancer le pipeline avec le meilleur modÃ¨le
python parse_and_enrich.py --model qwen2.5:14b && python generate_report.py

# 5. VÃ©rifier les rÃ©sultats
xdg-open output/rapport.pdf
```

## ðŸ’¡ Astuces

- **Multi-clients**: CrÃ©er un config.yaml par client
- **Versioning**: Dater les rapports (rapport_2025-11-05.pdf)
- **Backup**: Sauvegarder findings_enrichis.json
- **ConfidentialitÃ©**: Ne pas commiter results/scans/ (dÃ©jÃ  dans .gitignore)
- **Meilleure qualitÃ©**: Utiliser `qwen2.5:14b` ou `qwen2.5:32b` (voir AI_MODELS_GUIDE.md)
- **Notes manuelles**: CrÃ©er des fichiers TXT avec vos observations, l'IA les comprendra!
- **Fichiers mixtes**: MÃ©langer scans automatiques et notes manuelles, tout fonctionne!
- **Encodage**: Fricadelle dÃ©tecte automatiquement l'encodage (UTF-8, Latin-1, etc.)

## ðŸ¤ Support

Pour toute question:
1. Lire `README.md` et `ARCHITECTURE.md`
2. VÃ©rifier les logs d'erreur
3. Tester avec les donnÃ©es d'exemple fournies

---

**Bon audit! ðŸ›¡ï¸**
